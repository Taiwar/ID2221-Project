services:
  namenode:
    build: ./hdfs
    hostname: namenode
    command: start-hadoop namenode
    ports:
      - 8020:8020 # RPC
      - 9975:9870 # WebUI
    volumes:
      - ./hdfs/conf/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./hdfs/conf/hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
      - ./hdfs/data:/opt/hdfs
    environment:
      HDFS_USER: hdfsuser
  datanode:
    build: ./hdfs
    command: start-hadoop datanode
    ports:
      - 9164:9864
    environment:
      HDFS_USER: hdfsuser
    volumes:
      - ./hdfs/conf/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./hdfs/conf/hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
      - ./hdfs/data:/opt/hdfs

  spark-notebook:
    image: jupyter/pyspark-notebook:hadoop-3
    command: ["start-notebook.sh", "--NotebookApp.token=''", "--NotebookApp.password=''"]
    ports:
      - 8888:8888  # WebUI
      - 4040:4040  # Spark WebUI when local session started
      - 20002:20002 # Spark Driver Port
