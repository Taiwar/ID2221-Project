{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "  .master(\"local[*]\")\\\n",
    "  .appName(\"Jupyter\")\\\n",
    "  .config('spark.driver.port', '20002')\\\n",
    "  .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T06:48:22.209934200Z",
     "start_time": "2024-09-18T06:47:33.090468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.remote(\"sc://localhost:20002\").getOrCreate()\n",
    "spark"
   ],
   "id": "7d7ab1f7958189e7",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SparkSession\n\u001B[1;32m----> 2\u001B[0m spark \u001B[38;5;241m=\u001B[39m \u001B[43mSparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuilder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mremote\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msc://localhost:20002\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetOrCreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m spark\n",
      "File \u001B[1;32mG:\\dev\\Uni\\SparkTest\\.venv\\Lib\\site-packages\\pyspark\\sql\\session.py:479\u001B[0m, in \u001B[0;36mSparkSession.Builder.getOrCreate\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    477\u001B[0m     os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSPARK_CONNECT_MODE_ENABLED\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    478\u001B[0m     opts[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspark.remote\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m url\n\u001B[1;32m--> 479\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mRemoteSparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuilder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mopts\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetOrCreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    480\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSPARK_LOCAL_REMOTE\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m os\u001B[38;5;241m.\u001B[39menviron:\n\u001B[0;32m    481\u001B[0m     url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msc://localhost\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32mG:\\dev\\Uni\\SparkTest\\.venv\\Lib\\site-packages\\pyspark\\sql\\connect\\session.py:220\u001B[0m, in \u001B[0;36mSparkSession.Builder.getOrCreate\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    218\u001B[0m     session \u001B[38;5;241m=\u001B[39m SparkSession\u001B[38;5;241m.\u001B[39m_default_session\n\u001B[0;32m    219\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m session \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 220\u001B[0m         session \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    221\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply_options(session)\n\u001B[0;32m    222\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m session\n",
      "File \u001B[1;32mG:\\dev\\Uni\\SparkTest\\.venv\\Lib\\site-packages\\pyspark\\sql\\connect\\session.py:211\u001B[0m, in \u001B[0;36mSparkSession.Builder.create\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    208\u001B[0m     session \u001B[38;5;241m=\u001B[39m SparkSession(connection\u001B[38;5;241m=\u001B[39mspark_remote)\n\u001B[0;32m    210\u001B[0m SparkSession\u001B[38;5;241m.\u001B[39m_set_default_and_active_session(session)\n\u001B[1;32m--> 211\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply_options\u001B[49m\u001B[43m(\u001B[49m\u001B[43msession\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m session\n",
      "File \u001B[1;32mG:\\dev\\Uni\\SparkTest\\.venv\\Lib\\site-packages\\pyspark\\sql\\connect\\session.py:183\u001B[0m, in \u001B[0;36mSparkSession.Builder._apply_options\u001B[1;34m(self, session)\u001B[0m\n\u001B[0;32m    181\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_options\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m    182\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 183\u001B[0m         \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    184\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    185\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;28mstr\u001B[39m(e))\n",
      "File \u001B[1;32mG:\\dev\\Uni\\SparkTest\\.venv\\Lib\\site-packages\\pyspark\\sql\\connect\\conf.py:41\u001B[0m, in \u001B[0;36mRuntimeConf.set\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m     39\u001B[0m op_set \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mConfigRequest\u001B[38;5;241m.\u001B[39mSet(pairs\u001B[38;5;241m=\u001B[39m[proto\u001B[38;5;241m.\u001B[39mKeyValue(key\u001B[38;5;241m=\u001B[39mkey, value\u001B[38;5;241m=\u001B[39mvalue)])\n\u001B[0;32m     40\u001B[0m operation \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mConfigRequest\u001B[38;5;241m.\u001B[39mOperation(\u001B[38;5;28mset\u001B[39m\u001B[38;5;241m=\u001B[39mop_set)\n\u001B[1;32m---> 41\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m(\u001B[49m\u001B[43moperation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m warn \u001B[38;5;129;01min\u001B[39;00m result\u001B[38;5;241m.\u001B[39mwarnings:\n\u001B[0;32m     43\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(warn)\n",
      "File \u001B[1;32mG:\\dev\\Uni\\SparkTest\\.venv\\Lib\\site-packages\\pyspark\\sql\\connect\\client\\core.py:1368\u001B[0m, in \u001B[0;36mSparkConnectClient.config\u001B[1;34m(self, operation)\u001B[0m\n\u001B[0;32m   1366\u001B[0m req\u001B[38;5;241m.\u001B[39moperation\u001B[38;5;241m.\u001B[39mCopyFrom(operation)\n\u001B[0;32m   1367\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1368\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mattempt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retrying\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m   1369\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mattempt\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m   1370\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stub\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mConfig\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_builder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmetadata\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mG:\\dev\\Uni\\SparkTest\\.venv\\Lib\\site-packages\\pyspark\\sql\\connect\\client\\core.py:1684\u001B[0m, in \u001B[0;36mRetrying.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1681\u001B[0m             backoff \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m random\u001B[38;5;241m.\u001B[39muniform(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jitter)\n\u001B[0;32m   1683\u001B[0m         logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRetrying call after \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbackoff\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m ms sleep\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1684\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sleep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbackoff\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1000.0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1685\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m AttemptManager(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_can_retry, retry_state)\n\u001B[0;32m   1687\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m retry_state\u001B[38;5;241m.\u001B[39mdone():\n\u001B[0;32m   1688\u001B[0m     \u001B[38;5;66;03m# Exceeded number of retries, throw last exception we had\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T06:48:44.886574Z",
     "start_time": "2024-09-18T06:48:44.886574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setAppName('hello').setMaster('spark://localhost:20002')\n",
    "sc = SparkContext(conf=conf)\n",
    "sc"
   ],
   "id": "b37f4dafd6c71bfa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from datetime import datetime, date\n",
    "import pandas as pd\n",
    "from pyspark.sql import Row\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    Row(a=1, b=2., c='string1', d=date(2000, 1, 1), e=datetime(2000, 1, 1, 12, 0)),\n",
    "    Row(a=2, b=3., c='string2', d=date(2000, 2, 1), e=datetime(2000, 1, 2, 12, 0)),\n",
    "    Row(a=4, b=5., c='string3', d=date(2000, 3, 1), e=datetime(2000, 1, 3, 12, 0))\n",
    "])\n",
    "df"
   ],
   "id": "813a1acea4ace5c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df.write.csv('mycsv.csv', header=\"true\", mode=\"overwrite\")\n",
    "df2 = spark.read.csv('mycsv.csv')\n",
    "df2.show()"
   ],
   "id": "b7a1c62f9c728dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df.write.csv('hdfs://namemode:8020/mycsv.csv')\n",
    "out_path = \"hdfs://namenode:8020/mycsv.csv\"\n",
    "df.repartition(1).write.option(\"header\", \"true\").csv(out_path, mode = 'append')"
   ],
   "id": "6b2902803b2c4344"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
